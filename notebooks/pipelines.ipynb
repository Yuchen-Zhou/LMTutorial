{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pipelines\n",
    "\n",
    "NLP任务：\n",
    "- 文本分类：例如情感分析、句子对等关系判断\n",
    "- 对文本中的词语进行分类：例如词性标注(POS)、命名实体识别(NER)等\n",
    "- 文本生成：例如填充预设的模版(prompt)、预测文本中被遮掩掉(masked)的词语\n",
    "- 从文本中抽取答案：例如根据给定的问题从一段文本中抽取对应的答案\n",
    "- 根据输入文本生成新的句子：例如文本翻译、自动摘要\n",
    "\n",
    "Transformer库最基础的对象是`pipeline()`函数，封装了预训练模型和对应的前处理和后处理环节。只需要输入文本，就能得到预期的答案。\n",
    "常见的pipelines有：\n",
    "- feature-extraction (获得文本的向量化表示)\n",
    "- fill-mask (填充被遮盖的词、片段)\n",
    "- ner (命名实体识别)\n",
    "- question-answering (自动问答)\n",
    "- sentiment-analysis (情感分析)\n",
    "- summarization (自动摘要)\n",
    "- text-generation (文本生成)\n",
    "- translation (机器翻译)\n",
    "- zero-shot-classification (零训练样本分类)\n"
   ],
   "id": "c8f75d4bef825c27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 情感分析\n",
    "借助情感分析pipeline，我们只需要输入文本，就可以得到其情感标签(积极/消极)以及对应的概率："
   ],
   "id": "4018e8e39c379a4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T13:08:45.665793Z",
     "start_time": "2025-02-18T13:08:44.330972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lib2to3.fixes.fix_input import context\n",
    "\n",
    "from torch.nn.functional import max_pool1d\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "result = classifier('I like you')\n",
    "print(result)\n",
    "results = classifier(\n",
    "    ['I like you', 'I hate you']\n",
    ")\n",
    "print(results)"
   ],
   "id": "cae00b0438638860",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}]\n",
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}, {'label': 'NEGATIVE', 'score': 0.9791242480278015}]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pipeline模型会自动完成以下三个步骤：\n",
    "1. 将文本预处理为模型可以理解的格式\n",
    "2. 将与处理好的文本送入模型\n",
    "3. 对模型的预测值进行后处理，输入人类可以理解的格式\n",
    "\n",
    "pipeline会自动选择合适的预训练模型来完成任务。例如对于情感分析，默认会选择微调好的英文情感模型`distilbert-base-uncased-finetuned-sst-2-english`"
   ],
   "id": "5d4b4214411e3153"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 零训练样本分类\n",
    "零训练样本分类pipeline允许我们在不提供任何标注数据的情况下自定义分类标签\n",
    "pipeline自动选择了预训练好的facebook/bart-large-mnli模型"
   ],
   "id": "faeff85d15b69c1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T13:48:52.886646Z",
     "start_time": "2025-02-18T13:48:47.169173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')\n",
    "result = classifier(\n",
    "    'This is a course about the Transformers library.',\n",
    "    candidate_labels = ['education', 'politics', 'business']\n",
    ")\n",
    "print(result)"
   ],
   "id": "57a6d34c42720bf0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'This is a course about the Transformers library.', 'labels': ['education', 'business', 'politics'], 'scores': [0.8719860911369324, 0.09406667947769165, 0.033947158604860306]}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 文本生成\n",
    "我们首先根据任务需要构建一个模版(prompt)，然后将其送入到模型中来生成后续文本"
   ],
   "id": "2fdb5af42b206fc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:04:08.743645Z",
     "start_time": "2025-02-18T14:03:02.855183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation')\n",
    "results = generator('In this course, we will teach you how to')\n",
    "print(results)\n",
    "results = generator('In this course, we will teach you how to',\n",
    "num_return_sequences=2,\n",
    "max_length=50)\n",
    "print(results)"
   ],
   "id": "1d742de154ba90b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04acd3ee30a94ebaa3c1d6188a54b819"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5f03d0a8f57465787fb2176d2283f2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "04d03dd53afe4b479bdd34a4595293c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d9947f3b61a4957b7edc1b9369fce18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "777d839467524661b9df1f7cc29cd96e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "866ab8b618ed41f9ad0ed0e912d96eb7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "213eec58961344a4a71f5de812e0c4f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to implement multi-instance polymorphism, i.e., adding non-recursive data expressions to any type, using a polymorphism of a class-level data-type. This means that you are'}]\n",
      "[{'generated_text': 'In this course, we will teach you how to make your own bread (i.e. raw and dry, using only the freshest ingredients). However, it is also important to ensure you are using only materials in your recipe, because most homemade'}, {'generated_text': 'In this course, we will teach you how to build fast virtual machines that run using an emulator emulator at 3.6×3.9 MB/sec or better. Our virtual machines will be run with Python 3.6.2, which is'}]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "pipeline选择了预训练好的gpt2模型来完成任务，我们也可以指定要使用的模型。下面我们将指定使用DeepSeek-R1模型",
   "id": "600c14c45d928e30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T14:53:42.115070Z",
     "start_time": "2025-02-18T14:50:16.377720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "results = generator('In this course, we will teach you how to',\n",
    "max_length=50,\n",
    "num_return_sequences=2)\n",
    "print(results)"
   ],
   "id": "fef4fdfc81234a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb101a6b2b0749fea6342aa5ad8e3875"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d912db54e1d4db5bba4885db07bd799"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3639785a130f4553b24072513b164a7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78abe7119fc64bbe8cba1763c05ed5aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8372a85e65d4dc2bc92dc3d465674fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa65783255e342eaaa8e032e3c91339f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f77651f402d24f09ac90d2a76834472d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to create the skills for self-awareness, self-management and self-healing into the lessons of a successful teacher. I hope you enjoy this course – read my introductory article on the psychology of self'}, {'generated_text': 'In this course, we will teach you how to apply to the class, as well as learn how to use that as part of your online course design.\\n\\nThis course will take you through the first three principles of online project management. How you'}]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-18T15:00:03.859247Z",
     "start_time": "2025-02-18T15:00:01.644171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 或者你可以使用专门用于生成中文古诗的`gpt2-chinese-poem'\n",
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation', model='uer/gpt2-chinese-poem')\n",
    "results = generator('[CLS] 日 照 香 炉 生 紫 烟 ，', max_length=50, num_return_sequences=2)\n",
    "print(results)"
   ],
   "id": "ba7d0043765ba6df",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '[CLS] 日 照 香 炉 生 紫 烟 ， 以 一 炉 峰 。 天 风 吹 灵 药 金 炉 ， 烟 清 佛 见 青 莲 蕊 。 岩 顶 雪 寒 石 乳 流 ， 山 中 云 暖 长 松 寿 。 不 因'}, {'generated_text': '[CLS] 日 照 香 炉 生 紫 烟 ， 曰 心 独 止 。 我 入 冥 行 莫 朝 ， 无 生 不 灭 将 依 理 。 不 至 此 何 空 焉 。 云 霄 难 越 与 么 共 ， 人 间'}]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 遮盖词填充\n",
    "给定一段部分词语被遮盖掉的文本，使用预训练模型来预测能填充这些位置的词语"
   ],
   "id": "85c50a185c50e6fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T01:01:50.823847Z",
     "start_time": "2025-02-19T01:01:30.293493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmask = pipeline('fill-mask')\n",
    "results = unmask('This course will teach you all about <mask> models.', top_k=2)\n",
    "print(results)"
   ],
   "id": "82f9a0639109db91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "56185c5597014651ac2c7631d1c9456c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "076e50060c6b496e895ecd1e43153876"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "386b415f396341ef85ad91a47cb50311"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bff2da26be004bf38e76851449b36a97"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39eaecafa49c44f380ff1dac6cd9f390"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c84b39dfad840e4b897e426dce28805"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.19198693335056305, 'token': 30412, 'token_str': ' mathematical', 'sequence': 'This course will teach you all about mathematical models.'}, {'score': 0.04209252446889877, 'token': 38163, 'token_str': ' computational', 'sequence': 'This course will teach you all about computational models.'}]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 命名实体识别\n",
    "命名实体识别(NER)pipeline负责从文本中抽取出指定类型的实体"
   ],
   "id": "314f48baaf83fa11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T01:04:36.739536Z",
     "start_time": "2025-02-19T01:03:42.512395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline('ner', grouped_entities=True)\n",
    "results = ner('My name is Chris and I work at Hangzhou JiyiTech in Hangzhou')\n",
    "print(results)"
   ],
   "id": "aa28046c69c8f35",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac634e47e6194ff99b8d0b611dda41d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6a013fbde804f9199f5b85bbb96652c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "004e4855fb4f47a79a361c71ba24bfc0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30c0bdefa0f0420d94ffa025ea2a321b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "/Users/zhouyuchen/miniconda3/envs/llm/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': np.float32(0.99943787), 'word': 'Chris', 'start': 11, 'end': 16}, {'entity_group': 'ORG', 'score': np.float32(0.9967356), 'word': 'Hangzhou JiyiTech', 'start': 31, 'end': 48}, {'entity_group': 'LOC', 'score': np.float32(0.9977745), 'word': 'Hangzhou', 'start': 52, 'end': 60}]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自动问答\n",
    "自动问答pipeline可以根据给定的上下文回答问题"
   ],
   "id": "1af90e51208a6825"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T01:07:57.944096Z",
     "start_time": "2025-02-19T01:07:42.058690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answer = pipeline('question-answering')\n",
    "answer = question_answer(\n",
    "    question='Where do I work',\n",
    "    context='My name is Chris and I work at HangzhouJiyiTech in Hangzhou'\n",
    ")\n",
    "print(answer)"
   ],
   "id": "943f5f8f74f3850c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e15c0a1241849ca9dcbfaa722a02db6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce48c152a8aa4a499e3dcc226dffdbb6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c65ae8e253654b759753a57083731c8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e47a78fe2364ff09768efa2d6de7c3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46f2b5ff2e21465f88d4e79a94d1e277"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.860968828201294, 'start': 31, 'end': 47, 'answer': 'HangzhouJiyiTech'}\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pipeline自动选择了在SQuAD数据上训练好的`distilbert-base`模型来完成任务。自动问答pipeline实际上是一个抽取式问答模型，即从给定的上下文中抽取答案，而不是生成答案。\n",
    "\n",
    "QA系统可以分为：\n",
    "- 抽取式QA(extractive QA)：假设答案就包含在文档中，因此直接从文档中抽取答案\n",
    "- 多选QA(multiple-choice QA)：从多个给定的选项中选择答案，相当于做阅读理解\n",
    "- 无约束QA(free-form QA)：直接生成答案文本，并对答案文本格式没有任何限制"
   ],
   "id": "9d2ea057261f036c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 自动摘要\n",
    "自动摘要pipeline可以将长文本压缩成短文本，并且还要尽可能保留原文的主要信息"
   ],
   "id": "692b7ee59661eb9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:35:16.784666Z",
     "start_time": "2025-02-19T02:34:08.803450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline('summarization')\n",
    "results = summarizer(\"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of\n",
    "    graduates in traditional engineering disciplines such as mechanical, civil,\n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of\n",
    "    the premier American universities engineering curricula now concentrate on\n",
    "    and encourage largely the study of engineering science. As a result, there\n",
    "    are declining offerings in engineering subjects dealing with infrastructure,\n",
    "    the environment, and related issues, and greater concentration on high\n",
    "    technology subjects, largely supporting increasingly complex scientific\n",
    "    developments. While the latter is important, it should not be at the expense\n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other\n",
    "    industrial countries in Europe and Asia, continue to encourage and advance\n",
    "    the teaching of engineering. Both China and India, respectively, graduate\n",
    "    six and eight times as many traditional engineers as does the United States.\n",
    "    Other industrial countries at minimum maintain their output, while America\n",
    "    suffers an increasingly serious decline in the number of engineering graduates\n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\")\n",
    "\n",
    "print(results)"
   ],
   "id": "4590425512311029",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "841bc9c62818444396b947b6ce6abaee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bdabd557982247978cd1430d7c500ff5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f832df1d44334cde9de244486600d07e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9c38f98c19240e58ef307788fe99573"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "441a759aa9924a62952622ad832cfcd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9e4b0dca3aa4f50bd564df48925d474"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' The number of engineering graduates in the United States has declined in recent years . China and India graduate six and eight times as many traditional engineers as the U.S. does . Rapidly developing economies such as China continue to encourage and advance the teaching of engineering . There are declining offerings in engineering subjects dealing with infrastructure, infrastructure, the environment, and related issues .'}]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## pipeline的原理",
   "id": "d4ce416a1a5758cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:38:51.219741Z",
     "start_time": "2025-02-19T02:38:49.912714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "result = classifier('I like you')\n",
    "print(result)"
   ],
   "id": "e3419168bcb4b63a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998695850372314}]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "pipeline进行了三个步骤\n",
    "\n",
    "1. 预处理，将原始文本转换为模型可以接受的输入格式\n",
    "2. 将处理好的输入送入模型\n",
    "3. 对模型的输出进行后处理，将其转换成人能看懂的方式\n",
    "\n",
    "## 使用分词器进行预处理\n",
    "\n",
    "神经网络无法直接处理文本，首先需要通过预处理将文本转换为模型可以理解的数字。\n",
    "\n",
    "1. 将输入切分为词语、子词或者符号，统称tokens\n",
    "2. 根据模型的词表将每个token映射到对应的token编号\n",
    "3. 根据模型的需要，添加一些额外的输入\n",
    "\n",
    "每个模型都有特定的预处理操作，可以使用`AutoTokenizer`类和它的`from_pretrained()`函数，移动根据模型的`checkpoint`名称来获取对应分词器。\n",
    "\n",
    "情感分析pipeline的默认checkpoint是`distilbert-base-uncased-finetuned-sst-2-english`, 下面我们手工下载并调用其分词器"
   ],
   "id": "70a7b98e3148b1e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:54:59.555909Z",
     "start_time": "2025-02-19T02:54:59.178433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a Huggingface course whole my life\",\n",
    "    \"I hate you so much\"\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)"
   ],
   "id": "34f8c141ca6daef5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2878,  2026,  2166,   102],\n",
      "        [  101,  1045,  5223,  2017,  2061,  2172,   102,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 将预处理好的输入送入模型\n",
    "预训练模型的下载方式和分词器(tokenizer)类似，Transformers提供了`AutoModel`类和对应的`from_pretrained()`函数。"
   ],
   "id": "634237071fd5f356"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:59:15.058674Z",
     "start_time": "2025-02-19T02:59:02.889578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model = AutoModel.from_pretrained(checkpoint)"
   ],
   "id": "4e8e897ff1f5b66",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22111ecf173e46aaaf8252e5bde041ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "预训练模型只包含基础的Transformer模块，对于给定的输入，它会输出一些神经元的值，称为hidden states或者特征(features)。对于NLP模型来说，可以理解为是文本的高维语义表示。这些hidden states通常会被输入到其他的模型部分，以完成特定的任务，例如送入到分类头中完成文本分类任务。",
   "id": "d0db54133deb0720"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transformer模块的输出是一个Batch size的三维张量，其中Batch Size表示每次输入的样本数量，即每次输入多少个句子；Sequence Length表示文本序列的长度，即每个句子被分为多少个token；Hidden size表示每一个token经过模型编码后的输出向量的维度",
   "id": "c5b227680fae6808"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T03:17:03.019102Z",
     "start_time": "2025-02-19T03:17:01.921670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModel.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a Huggingface course whole my life\",\n",
    "    \"I hate you so much\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)"
   ],
   "id": "ad7fc9c194d407f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 15, 768])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 对模型输出进行后处理\n",
    "由于模型的输出只是一些数值，因此并不适合人类阅读"
   ],
   "id": "e03dd7981cef333c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T03:20:07.704169Z",
     "start_time": "2025-02-19T03:20:06.937510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "raw_inputs = [\n",
    "    \"I've been waiting for a Huggingface course whole my life\",\n",
    "    \"I hate you so much\"\n",
    "]\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "print(outputs.logits)"
   ],
   "id": "853af5035bf59b36",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2530,  1.2837],\n",
      "        [ 3.8375, -3.1348]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "模型对一个句子的输出是`[-1.2530,  1.2837]`，对第二个句子输出`[ 3.8375, -3.1348]`，这些并不是概率值，而是模型最后一层输出的logits值，还需要过一层Softmax",
   "id": "2ccc7a0a643d9efc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T03:23:04.171653Z",
     "start_time": "2025-02-19T03:23:04.162783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "print(predictions)"
   ],
   "id": "6f56661811f648e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3325e-02, 9.2668e-01],\n",
      "        [9.9906e-01, 9.3657e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T03:24:09.011775Z",
     "start_time": "2025-02-19T03:24:09.009639Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.config.id2label)",
   "id": "7a9dfa24758bb888",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NEGATIVE', 1: 'POSITIVE'}\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3dfa4326b7524fd2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
